{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Uploader:\n",
    "## A script for importing a SQLite database into various database services using SQLAlchemy, Pandas, and other tools\n",
    "\n",
    "Kenneth Burchfiel\n",
    "\n",
    "Released under the MIT License\n",
    "\n",
    "This program provides scripts for importing a SQLite database into the following databases:\n",
    "1. Amazon Web Services (AWS)\n",
    "2. Google Cloud Platform (GCP)\n",
    "3. Microsoft Azure\n",
    "4. Snowflake\n",
    "5. Airtable (partial import only due to space restrictions)\n",
    "6. Heroku\n",
    "7. Databricks\n",
    "\n",
    "The AWS, GCP, and Azure databases all use PostgreSQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time() # Allows the program's runtime to be measured\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from pyairtable import Api, Base, Table # from https://pyairtable.readthedocs.io/en/latest/api.html\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyodbc\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make my database passwords more secure, I will access them by first opening a file that contains the path to my passwords folder, then opening the files within the passwords folder that store the actual passwords. Each file contains only one password. You will of course need to modify this code to point it towards your own passwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\kburc\\D1V1\\Documents\\!Dell64docs\\Programming\\py\\kjb3_programs\\key_paths\\path_to_keys_folder.txt') as file:\n",
    "    path_to_keys_folder = file.readline() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path_to_keys_folder+'\\\\kb_ind_study_aws_db_pw.txt') as file:\n",
    "#     aws_pw = file.readline()\n",
    "\n",
    "with open(path_to_keys_folder+'\\\\kb-cheaper-aws-db_pw.txt') as file:\n",
    "    aws_pw = file.readline()\n",
    "\n",
    "with open(path_to_keys_folder+'\\\\kb_ind_study_gcp_db_pw.txt') as file:\n",
    "    gcp_pw = file.readline()\n",
    "\n",
    "with open(path_to_keys_folder+'\\\\kb_ind_study_azure_db_pw.txt') as file:\n",
    "    azure_pw = file.readline()\n",
    "\n",
    "with open(path_to_keys_folder+'\\\\snowflake_pw.txt') as file:\n",
    "    snowflake_pw = file.readline()\n",
    "\n",
    "with open(path_to_keys_folder+'\\\\airtable_api_key.txt') as file:\n",
    "    airtable_key = file.readline()\n",
    " \n",
    "with open(path_to_keys_folder+'\\\\heroku_db_pw.txt') as file:\n",
    "    heroku_pw = file.readline()\n",
    "\n",
    "with open(path_to_keys_folder+'\\\\databricks_paid_account_token.txt') as file:\n",
    "    databricks_paid_account_token = file.readline()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block specifies which databases the program should connect to, upload to, and import from. These flags allow you to save time and perhaps money as well by skipping unnecessary uploads and exports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_to_sqlite = True\n",
    "connect_to_aws = False\n",
    "connect_to_gcp = False\n",
    "connect_to_azure = False\n",
    "connect_to_snowflake = False\n",
    "connect_to_airtable = False\n",
    "connect_to_heroku = False\n",
    "connect_to_databricks = False\n",
    "\n",
    "upload_to_aws = False\n",
    "upload_to_gcp = False\n",
    "upload_to_azure = False\n",
    "upload_to_snowflake = False\n",
    "upload_to_airtable = False\n",
    "upload_to_heroku = False\n",
    "upload_to_databricks = False\n",
    "\n",
    "\n",
    "import_from_aws = False\n",
    "import_from_gcp = False\n",
    "import_from_azure = False\n",
    "import_from_snowflake = False\n",
    "import_from_heroku = False\n",
    "import_from_databricks = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Establishing Database Connections\n",
    "\n",
    "The code below establishes connections to each database. Code for generating the SQLite database, whose contents will be exported to the other database types in this program, can be found within the SQLite Database Builder script within this project.\n",
    "\n",
    "In order to determine which materials to enter into the connection strings, you will need to first create a database online [although that itself may be possible through a Python script], then retrieve the credentials listed for that database.\n",
    "\n",
    "SQLAlchemy was chosen for most of these databases because it permits the use of the to_sql() Pandas function, which greatly simplifies the database export process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if connect_to_sqlite == True: \n",
    "    sqlalchemy_sqlite_engine = sqlalchemy.create_engine('sqlite:///data\\\\sqlite_database.db')  # Based on https://docs.sqlalchemy.org/en/13/dialects/sqlite.html#connect-strings\n",
    "    # This database was created within sqlite_database_builder.ipynb.\n",
    "\n",
    "\n",
    "if connect_to_aws == True:\n",
    "    aws_sqlalchemy_psql_engine = sqlalchemy.create_engine('postgresql://kburchfiel:'+str(aws_pw)+'@kb-cheaper-aws-db.cquawwv3qwid.us-east-1.rds.amazonaws.com:5432/postgres')\n",
    "# Based on https://stackoverflow.com/a/58208015/13097194\n",
    "# That answer can also be derived from:\n",
    "# 1. https://docs.sqlalchemy.org/en/14/core/engines.html\n",
    "# And: 2. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html\n",
    "\n",
    "\n",
    "# SQLAlchemy engine for connecting to Google Cloud Platform SQL database\n",
    "# The code is based on Google code found at https://cloud.google.com/sql/docs/postgres/samples/cloud-sql-postgres-sqlalchemy-create-tcp. That code is licensed under the Apache 2.0 license.\n",
    "if connect_to_gcp == True:\n",
    "    gcp_sqlalchemy_psql_engine = sqlalchemy.create_engine(\n",
    "        # Equivalent URL:\n",
    "        # postgresql+pg8000://<db_user>:<db_pass>@<db_host>:<db_port>/<db_name>\n",
    "        sqlalchemy.engine.url.URL.create(\n",
    "            drivername=\"postgresql\",\n",
    "            username='kb_gcp_db',  # e.g. \"my-database-user\"\n",
    "            password=gcp_pw,  # e.g. \"my-database-password\"\n",
    "            host='34.135.185.218',  # e.g. \"127.0.0.1\"\n",
    "            port=5432,  # e.g. 5432\n",
    "            database='postgres'  # e.g. \"my-database-name\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "if connect_to_azure == True:\n",
    "   azure_sqlalchemy_psql_engine = sqlalchemy.create_engine('postgresql://kbindstudy:'+str(azure_pw)+'@kb-ind-study-azure-server.postgres.database.azure.com/postgres?sslmode=require')\n",
    "   # This string is based both on the Amazon connection string and the 'PostgreSQL connection URL' shown on the 'Connection strings' page within the Azure Database site.\n",
    "\n",
    "\n",
    "# I believe the following code was derived from the AWS/GCP/Azure connection strings, as the format is identical.\n",
    "if connect_to_heroku == True:\n",
    "    heroku_sqlalchemy_psql_engine = sqlalchemy.create_engine('postgresql://wtgddsmdmsipoo:'+str(heroku_pw)+'@ec2-23-23-199-57.compute-1.amazonaws.com:5432/ddc9jvn58br3tc')\n",
    "\n",
    "# The following code derived from https://docs.snowflake.com/en/user-guide/sqlalchemy.html#connection-string-examples\n",
    "if connect_to_snowflake == True:\n",
    "    snowflake_engine = sqlalchemy.create_engine('snowflake://KBURCHFIEL:'+str(snowflake_pw)+'@RV85777.east-us-2.azure/KB_SNOWFLAKE_DB/PUBLIC')\n",
    "\n",
    "\n",
    "\n",
    "if connect_to_databricks == True:\n",
    "    # Pyodbc databricks setup. Source: https://docs.databricks.com/dev-tools/pyodbc.html#windows\n",
    "    # Pyodbc was used instead of SQLAlchemy because the SQLAlchemy connector required downloading Microsoft's Visual Studio Build tools, and I don't think I would be able to use those tools for free in certain commercial use cases. Therefore, I opted for a pyodbc setup.\n",
    "    databricks_pyodbc_connection = pyodbc.connect(\"DSN=Databricks_Cluster\", autocommit=True)\n",
    "    databricks_pyodbc_cursor = databricks_pyodbc_connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I strongly prefer using SQLAlchemy when possible due to its compatibility with the to_sql Pandas function, I also wanted to try out an alternate connection method. \n",
    "\n",
    "The following code derives from https://docs.microsoft.com/en-us/azure/postgresql/connect-python . It demonstrates how psycopg2 can be used as an alternative to SQLAlchemy. The code works but is redundant given that SQLAlchemy already works, so I commented it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tried connecting via pyodbc but it didn't work, so psycopg2 looks like a better option.\n",
    "# host = \"kb-ind-study-azure-server.postgres.database.azure.com\"\n",
    "# dbname = \"postgres\"\n",
    "# user = \"kbindstudy\"\n",
    "# password = str(azure_pw)\n",
    "# sslmode = \"require\"\n",
    "\n",
    "# # Construct connection string\n",
    "# conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
    "# psycopg2_azure_connection = psycopg2.connect(conn_string)\n",
    "# print(\"Connection established\")\n",
    "\n",
    "# psycopg2_azure_cursor = psycopg2_azure_connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Importing data from SQLite database \n",
    "\n",
    "I will need to import data from my SQLite database in order to upload it into my other databases. First, I will generate a list of all tables within the database. Using this list instead of hard-coding the table names makes the code more portable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flights', 'photos', 'steps', 'music']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlite_table_query = sqlalchemy_sqlite_engine.execute(\"Select name from sqlite_schema where type = 'table'\")\n",
    "# This method for extracting all tables derived from https://www.kite.com/python/answers/how-to-list-tables-using-sqlite3-in-python , although I used sqlite_schema instead of sqlite_master . See also: https://www.sqlite.org/schematab.html\n",
    "sqlite_table_tuple_list = sqlite_table_query.fetchall()\n",
    "sqlite_table_list = [query[0] for query in sqlite_table_tuple_list] # List comprehension extracts only the first part of each tuple stored in table_list.\n",
    "sqlite_table_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block allows you to determine which tables are already present within a PostgreSQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you may wish to clear one or more databases of tables that you had previously uploaded. The following function accomplishes this task for PostgreSQL databases. However, the function is not necessary for the import process to work (since to_sql lets you replace pre-existing tables with newer versions, making a prior drop unnecessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_all_public_tables_from_db(connection):\n",
    "    db_tables_query = connection.execute(\"Select tablename from pg_tables where schemaname = 'public'\") # See https://www.postgresql.org/docs/8.0/view-pg-tables.html\n",
    "\n",
    "    db_table_tuple_list = db_tables_query.fetchall()\n",
    "    db_table_list = [query[0] for query in db_table_tuple_list]\n",
    "    if len(db_table_list) == 0:\n",
    "        print(\"No public tables to drop.\")\n",
    "        return\n",
    "    print(len(db_table_list))\n",
    "    tables_as_string = (\", \").join(db_table_list) # Joining the table names enables them to be dropped within a single line of SQL code.\n",
    "    print(\"dropping tables:\",tables_as_string)\n",
    "    connection.execute(\"drop table \" + tables_as_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "dropping tables: flights, photos, steps, music\n",
      "4\n",
      "dropping tables: flights, photos, steps, music\n",
      "4\n",
      "dropping tables: flights, photos, steps, music\n"
     ]
    }
   ],
   "source": [
    "# drop_all_public_tables_from_db(connection = azure_sqlalchemy_psql_engine)\n",
    "# drop_all_public_tables_from_db(connection = gcp_sqlalchemy_psql_engine)\n",
    "# drop_all_public_tables_from_db(connection = aws_sqlalchemy_psql_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether a particular connection worked, you can use the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_music_from_db = pd.read_sql(\"Select * from music\", con = con_for_export)\n",
    "# df_music_from_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code iterates through sqlite_table_list to read data from the SQLite database into DataFrames, then append each of these databases to a list of DataFrames (table_to_df_list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_to_df_list = []\n",
    "for table in sqlite_table_list:\n",
    "    table_to_df_list.append(pd.read_sql(\"Select * from \"+str(table), con = sqlalchemy_sqlite_engine, index_col = 'index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the four tables now stored in table_to_df_list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPARTURES_SCHEDULED</th>\n",
       "      <th>DEPARTURES_PERFORMED</th>\n",
       "      <th>PAYLOAD</th>\n",
       "      <th>SEATS</th>\n",
       "      <th>PASSENGERS</th>\n",
       "      <th>FREIGHT</th>\n",
       "      <th>MAIL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>RAMP_TO_RAMP</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>...</th>\n",
       "      <th>Code_y</th>\n",
       "      <th>Plane_Group_Text</th>\n",
       "      <th>Code</th>\n",
       "      <th>Plane_Config_Text</th>\n",
       "      <th>origin_iata_code</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_lon</th>\n",
       "      <th>destination_iata_code</th>\n",
       "      <th>destination_lat</th>\n",
       "      <th>destination_lon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21502.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>IAD</td>\n",
       "      <td>38.944</td>\n",
       "      <td>-77.456</td>\n",
       "      <td>FLL</td>\n",
       "      <td>26.072</td>\n",
       "      <td>-80.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64506.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>IAD</td>\n",
       "      <td>38.944</td>\n",
       "      <td>-77.456</td>\n",
       "      <td>JFK</td>\n",
       "      <td>40.640</td>\n",
       "      <td>-73.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21502.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>IAH</td>\n",
       "      <td>29.980</td>\n",
       "      <td>-95.340</td>\n",
       "      <td>SAV</td>\n",
       "      <td>32.127</td>\n",
       "      <td>-81.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21502.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>ILM</td>\n",
       "      <td>34.271</td>\n",
       "      <td>-77.903</td>\n",
       "      <td>RDU</td>\n",
       "      <td>35.877</td>\n",
       "      <td>-78.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>IND</td>\n",
       "      <td>39.717</td>\n",
       "      <td>-86.294</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482268</th>\n",
       "      <td>1166.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>1049400.0</td>\n",
       "      <td>5247.0</td>\n",
       "      <td>3646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>27284.0</td>\n",
       "      <td>21338.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Piston, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>ACK</td>\n",
       "      <td>41.253</td>\n",
       "      <td>-70.060</td>\n",
       "      <td>BOS</td>\n",
       "      <td>42.364</td>\n",
       "      <td>-71.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482269</th>\n",
       "      <td>1188.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>1069200.0</td>\n",
       "      <td>5346.0</td>\n",
       "      <td>3573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>27799.0</td>\n",
       "      <td>21740.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Piston, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>BOS</td>\n",
       "      <td>42.364</td>\n",
       "      <td>-71.005</td>\n",
       "      <td>ACK</td>\n",
       "      <td>41.253</td>\n",
       "      <td>-70.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482270</th>\n",
       "      <td>1216.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>1094400.0</td>\n",
       "      <td>5472.0</td>\n",
       "      <td>3827.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>28454.0</td>\n",
       "      <td>22253.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Piston, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>ACK</td>\n",
       "      <td>41.253</td>\n",
       "      <td>-70.060</td>\n",
       "      <td>BOS</td>\n",
       "      <td>42.364</td>\n",
       "      <td>-71.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482271</th>\n",
       "      <td>1258.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>1132200.0</td>\n",
       "      <td>5661.0</td>\n",
       "      <td>4056.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>29437.0</td>\n",
       "      <td>23021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Piston, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>BOS</td>\n",
       "      <td>42.364</td>\n",
       "      <td>-71.005</td>\n",
       "      <td>ACK</td>\n",
       "      <td>41.253</td>\n",
       "      <td>-70.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482272</th>\n",
       "      <td>2170.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>74400.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Helicopter/Stol</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482273 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DEPARTURES_SCHEDULED  DEPARTURES_PERFORMED    PAYLOAD   SEATS  \\\n",
       "index                                                                   \n",
       "0                        0.0                   1.0    21502.0    76.0   \n",
       "1                        0.0                   3.0    64506.0   228.0   \n",
       "2                        0.0                   1.0    21502.0    76.0   \n",
       "3                        0.0                   1.0    21502.0    76.0   \n",
       "4                        0.0                   1.0    12500.0    50.0   \n",
       "...                      ...                   ...        ...     ...   \n",
       "482268                1166.0                 583.0  1049400.0  5247.0   \n",
       "482269                1188.0                 594.0  1069200.0  5346.0   \n",
       "482270                1216.0                 608.0  1094400.0  5472.0   \n",
       "482271                1258.0                 629.0  1132200.0  5661.0   \n",
       "482272                2170.0                  44.0    74400.0   264.0   \n",
       "\n",
       "        PASSENGERS  FREIGHT  MAIL  DISTANCE  RAMP_TO_RAMP  AIR_TIME  ...  \\\n",
       "index                                                                ...   \n",
       "0              3.0      0.0   0.0     901.0         170.0     140.0  ...   \n",
       "1             75.0      0.0   0.0     228.0         219.0     140.0  ...   \n",
       "2             64.0      0.0   0.0     851.0         144.0     114.0  ...   \n",
       "3             55.0      0.0   0.0     122.0          58.0      31.0  ...   \n",
       "4             34.0      0.0   0.0     133.0          49.0      29.0  ...   \n",
       "...            ...      ...   ...       ...           ...       ...  ...   \n",
       "482268      3646.0      0.0   0.0      91.0       27284.0   21338.0  ...   \n",
       "482269      3573.0      0.0   0.0      91.0       27799.0   21740.0  ...   \n",
       "482270      3827.0      0.0   0.0      91.0       28454.0   22253.0  ...   \n",
       "482271      4056.0      0.0   0.0      91.0       29437.0   23021.0  ...   \n",
       "482272         0.0      0.0  44.0      59.0        1860.0       0.0  ...   \n",
       "\n",
       "       Code_y  Plane_Group_Text Code        Plane_Config_Text  \\\n",
       "index                                                           \n",
       "0           6     Jet, 2-Engine    1  Passenger Configuration   \n",
       "1           6     Jet, 2-Engine    1  Passenger Configuration   \n",
       "2           6     Jet, 2-Engine    1  Passenger Configuration   \n",
       "3           6     Jet, 2-Engine    1  Passenger Configuration   \n",
       "4           6     Jet, 2-Engine    1  Passenger Configuration   \n",
       "...       ...               ...  ...                      ...   \n",
       "482268      1  Piston, 2-Engine    1  Passenger Configuration   \n",
       "482269      1  Piston, 2-Engine    1  Passenger Configuration   \n",
       "482270      1  Piston, 2-Engine    1  Passenger Configuration   \n",
       "482271      1  Piston, 2-Engine    1  Passenger Configuration   \n",
       "482272      3   Helicopter/Stol    1  Passenger Configuration   \n",
       "\n",
       "       origin_iata_code origin_lat origin_lon  destination_iata_code  \\\n",
       "index                                                                  \n",
       "0                   IAD     38.944    -77.456                    FLL   \n",
       "1                   IAD     38.944    -77.456                    JFK   \n",
       "2                   IAH     29.980    -95.340                    SAV   \n",
       "3                   ILM     34.271    -77.903                    RDU   \n",
       "4                   IND     39.717    -86.294                   None   \n",
       "...                 ...        ...        ...                    ...   \n",
       "482268              ACK     41.253    -70.060                    BOS   \n",
       "482269              BOS     42.364    -71.005                    ACK   \n",
       "482270              ACK     41.253    -70.060                    BOS   \n",
       "482271              BOS     42.364    -71.005                    ACK   \n",
       "482272             None        NaN        NaN                   None   \n",
       "\n",
       "        destination_lat  destination_lon  \n",
       "index                                     \n",
       "0                26.072          -80.153  \n",
       "1                40.640          -73.779  \n",
       "2                32.127          -81.202  \n",
       "3                35.877          -78.787  \n",
       "4                   NaN              NaN  \n",
       "...                 ...              ...  \n",
       "482268           42.364          -71.005  \n",
       "482269           41.253          -70.060  \n",
       "482270           42.364          -71.005  \n",
       "482271           41.253          -70.060  \n",
       "482272              NaN              NaN  \n",
       "\n",
       "[482273 rows x 62 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_to_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>size</th>\n",
       "      <th>created_date</th>\n",
       "      <th>modified_date</th>\n",
       "      <th>gcs_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10086848403_b33a695758_o.jpg</td>\n",
       "      <td>1027202</td>\n",
       "      <td>Mon Sep 13 23:45:07 2021</td>\n",
       "      <td>Mon Sep 13 20:44:36 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10171744985_76f8973d6b_o.jpg</td>\n",
       "      <td>160300</td>\n",
       "      <td>Mon Sep 13 23:45:07 2021</td>\n",
       "      <td>Mon Sep 13 01:42:14 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10822424126_91be9abb6d_o.jpg</td>\n",
       "      <td>402898</td>\n",
       "      <td>Mon Sep 13 23:45:07 2021</td>\n",
       "      <td>Mon Sep 13 01:42:25 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10843413524_82caa8b0f8_o.jpg</td>\n",
       "      <td>7405423</td>\n",
       "      <td>Mon Sep 13 23:45:07 2021</td>\n",
       "      <td>Mon Sep 13 01:32:56 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11309341065_6fcfbee752_o.jpg</td>\n",
       "      <td>466609</td>\n",
       "      <td>Mon Sep 13 23:45:07 2021</td>\n",
       "      <td>Mon Sep 13 20:38:00 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>S69-34316~orig.jpg</td>\n",
       "      <td>1339165</td>\n",
       "      <td>Mon Sep 13 23:45:08 2021</td>\n",
       "      <td>Mon Sep 13 01:45:54 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>S71-41357~orig.jpg</td>\n",
       "      <td>2103357</td>\n",
       "      <td>Mon Sep 13 23:45:08 2021</td>\n",
       "      <td>Mon Sep 13 20:48:45 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>S71-41759~orig.jpg</td>\n",
       "      <td>1470210</td>\n",
       "      <td>Mon Sep 13 23:45:08 2021</td>\n",
       "      <td>Mon Sep 13 20:07:29 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>sts061-s-104~orig.jpg</td>\n",
       "      <td>2055089</td>\n",
       "      <td>Mon Sep 13 23:45:08 2021</td>\n",
       "      <td>Mon Sep 13 20:58:49 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>STSCPanel.jpg</td>\n",
       "      <td>4307564</td>\n",
       "      <td>Mon Sep 13 23:45:08 2021</td>\n",
       "      <td>Mon Sep 13 21:25:57 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          file_name     size              created_date  \\\n",
       "index                                                                    \n",
       "0      10086848403_b33a695758_o.jpg  1027202  Mon Sep 13 23:45:07 2021   \n",
       "1      10171744985_76f8973d6b_o.jpg   160300  Mon Sep 13 23:45:07 2021   \n",
       "2      10822424126_91be9abb6d_o.jpg   402898  Mon Sep 13 23:45:07 2021   \n",
       "3      10843413524_82caa8b0f8_o.jpg  7405423  Mon Sep 13 23:45:07 2021   \n",
       "4      11309341065_6fcfbee752_o.jpg   466609  Mon Sep 13 23:45:07 2021   \n",
       "...                             ...      ...                       ...   \n",
       "128              S69-34316~orig.jpg  1339165  Mon Sep 13 23:45:08 2021   \n",
       "129              S71-41357~orig.jpg  2103357  Mon Sep 13 23:45:08 2021   \n",
       "130              S71-41759~orig.jpg  1470210  Mon Sep 13 23:45:08 2021   \n",
       "131           sts061-s-104~orig.jpg  2055089  Mon Sep 13 23:45:08 2021   \n",
       "132                   STSCPanel.jpg  4307564  Mon Sep 13 23:45:08 2021   \n",
       "\n",
       "                  modified_date  \\\n",
       "index                             \n",
       "0      Mon Sep 13 20:44:36 2021   \n",
       "1      Mon Sep 13 01:42:14 2021   \n",
       "2      Mon Sep 13 01:42:25 2021   \n",
       "3      Mon Sep 13 01:32:56 2021   \n",
       "4      Mon Sep 13 20:38:00 2021   \n",
       "...                         ...   \n",
       "128    Mon Sep 13 01:45:54 2021   \n",
       "129    Mon Sep 13 20:48:45 2021   \n",
       "130    Mon Sep 13 20:07:29 2021   \n",
       "131    Mon Sep 13 20:58:49 2021   \n",
       "132    Mon Sep 13 21:25:57 2021   \n",
       "\n",
       "                                                 gcs_url  \n",
       "index                                                     \n",
       "0      https://storage.googleapis.com/kb_sample_datab...  \n",
       "1      https://storage.googleapis.com/kb_sample_datab...  \n",
       "2      https://storage.googleapis.com/kb_sample_datab...  \n",
       "3      https://storage.googleapis.com/kb_sample_datab...  \n",
       "4      https://storage.googleapis.com/kb_sample_datab...  \n",
       "...                                                  ...  \n",
       "128    https://storage.googleapis.com/kb_sample_datab...  \n",
       "129    https://storage.googleapis.com/kb_sample_datab...  \n",
       "130    https://storage.googleapis.com/kb_sample_datab...  \n",
       "131    https://storage.googleapis.com/kb_sample_datab...  \n",
       "132    https://storage.googleapis.com/kb_sample_datab...  \n",
       "\n",
       "[133 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_to_df_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-20 19:05:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-20 19:38:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-20 19:39:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-20 19:40:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-20 19:41:00.000000</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529251</th>\n",
       "      <td>2021-09-16 18:26:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529252</th>\n",
       "      <td>2021-09-16 18:27:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529253</th>\n",
       "      <td>2021-09-16 18:28:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529254</th>\n",
       "      <td>2021-09-16 18:29:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529255</th>\n",
       "      <td>2021-09-16 18:30:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dateTime  value\n",
       "index                                    \n",
       "0       2020-01-20 19:05:00.000000      0\n",
       "1       2020-01-20 19:38:00.000000      0\n",
       "2       2020-01-20 19:39:00.000000      0\n",
       "3       2020-01-20 19:40:00.000000      0\n",
       "4       2020-01-20 19:41:00.000000     61\n",
       "...                            ...    ...\n",
       "529251  2021-09-16 18:26:00.000000      0\n",
       "529252  2021-09-16 18:27:00.000000      0\n",
       "529253  2021-09-16 18:28:00.000000      0\n",
       "529254  2021-09-16 18:29:00.000000      0\n",
       "529255  2021-09-16 18:30:00.000000      0\n",
       "\n",
       "[529256 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_to_df_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>music_file_name</th>\n",
       "      <th>music_size</th>\n",
       "      <th>music_created_date</th>\n",
       "      <th>music_modified_date</th>\n",
       "      <th>music_gcs_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_0.mp3</td>\n",
       "      <td>94391</td>\n",
       "      <td>Thu Sep 16 15:32:20 2021</td>\n",
       "      <td>Thu Sep 16 15:32:27 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1.mp3</td>\n",
       "      <td>114244</td>\n",
       "      <td>Thu Sep 16 15:33:02 2021</td>\n",
       "      <td>Thu Sep 16 15:40:16 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_10.mp3</td>\n",
       "      <td>73493</td>\n",
       "      <td>Thu Sep 16 15:34:14 2021</td>\n",
       "      <td>Thu Sep 16 15:34:14 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_11.mp3</td>\n",
       "      <td>94391</td>\n",
       "      <td>Thu Sep 16 15:34:18 2021</td>\n",
       "      <td>Thu Sep 16 15:34:18 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_12.mp3</td>\n",
       "      <td>64088</td>\n",
       "      <td>Thu Sep 16 15:34:22 2021</td>\n",
       "      <td>Thu Sep 16 15:34:22 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>sample_62.mp3</td>\n",
       "      <td>73493</td>\n",
       "      <td>Thu Sep 16 15:38:15 2021</td>\n",
       "      <td>Thu Sep 16 15:38:15 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>sample_63.mp3</td>\n",
       "      <td>103795</td>\n",
       "      <td>Thu Sep 16 15:38:19 2021</td>\n",
       "      <td>Thu Sep 16 15:38:19 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>sample_7.mp3</td>\n",
       "      <td>64088</td>\n",
       "      <td>Thu Sep 16 15:34:03 2021</td>\n",
       "      <td>Thu Sep 16 15:34:03 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>sample_8.mp3</td>\n",
       "      <td>73493</td>\n",
       "      <td>Thu Sep 16 15:34:06 2021</td>\n",
       "      <td>Thu Sep 16 15:34:06 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>sample_9.mp3</td>\n",
       "      <td>64088</td>\n",
       "      <td>Thu Sep 16 15:34:10 2021</td>\n",
       "      <td>Thu Sep 16 15:34:10 2021</td>\n",
       "      <td>https://storage.googleapis.com/kb_sample_datab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      music_file_name  music_size        music_created_date  \\\n",
       "index                                                         \n",
       "0        sample_0.mp3       94391  Thu Sep 16 15:32:20 2021   \n",
       "1        sample_1.mp3      114244  Thu Sep 16 15:33:02 2021   \n",
       "2       sample_10.mp3       73493  Thu Sep 16 15:34:14 2021   \n",
       "3       sample_11.mp3       94391  Thu Sep 16 15:34:18 2021   \n",
       "4       sample_12.mp3       64088  Thu Sep 16 15:34:22 2021   \n",
       "...               ...         ...                       ...   \n",
       "59      sample_62.mp3       73493  Thu Sep 16 15:38:15 2021   \n",
       "60      sample_63.mp3      103795  Thu Sep 16 15:38:19 2021   \n",
       "61       sample_7.mp3       64088  Thu Sep 16 15:34:03 2021   \n",
       "62       sample_8.mp3       73493  Thu Sep 16 15:34:06 2021   \n",
       "63       sample_9.mp3       64088  Thu Sep 16 15:34:10 2021   \n",
       "\n",
       "            music_modified_date  \\\n",
       "index                             \n",
       "0      Thu Sep 16 15:32:27 2021   \n",
       "1      Thu Sep 16 15:40:16 2021   \n",
       "2      Thu Sep 16 15:34:14 2021   \n",
       "3      Thu Sep 16 15:34:18 2021   \n",
       "4      Thu Sep 16 15:34:22 2021   \n",
       "...                         ...   \n",
       "59     Thu Sep 16 15:38:15 2021   \n",
       "60     Thu Sep 16 15:38:19 2021   \n",
       "61     Thu Sep 16 15:34:03 2021   \n",
       "62     Thu Sep 16 15:34:06 2021   \n",
       "63     Thu Sep 16 15:34:10 2021   \n",
       "\n",
       "                                           music_gcs_url  \n",
       "index                                                     \n",
       "0      https://storage.googleapis.com/kb_sample_datab...  \n",
       "1      https://storage.googleapis.com/kb_sample_datab...  \n",
       "2      https://storage.googleapis.com/kb_sample_datab...  \n",
       "3      https://storage.googleapis.com/kb_sample_datab...  \n",
       "4      https://storage.googleapis.com/kb_sample_datab...  \n",
       "...                                                  ...  \n",
       "59     https://storage.googleapis.com/kb_sample_datab...  \n",
       "60     https://storage.googleapis.com/kb_sample_datab...  \n",
       "61     https://storage.googleapis.com/kb_sample_datab...  \n",
       "62     https://storage.googleapis.com/kb_sample_datab...  \n",
       "63     https://storage.googleapis.com/kb_sample_datab...  \n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_to_df_list[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following truncated versions of the steps and flights tables will be used for the Airtable import given Airtable's size restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steps_truncated = table_to_df_list[sqlite_table_list.index('steps')].iloc[0:400] # .index is used to return the entry in table_to_df_list that was based on the steps table. This works because DataFrames were added to table_to_df_list in the same order that the tables appear in sqlite_table_list.\n",
    "df_steps_truncated.to_csv('data\\\\df_steps_1st_400_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights_truncated = table_to_df_list[sqlite_table_list.index('flights')].iloc[0:400]\n",
    "df_flights_truncated.to_csv('data\\\\df_flights_1st_400_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-20 19:05:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-20 19:38:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-20 19:39:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-20 19:40:00.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-20 19:41:00.000000</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2020-01-21 06:57:00.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2020-01-21 06:58:00.000000</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2020-01-21 06:59:00.000000</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2020-01-21 07:00:00.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2020-01-21 07:01:00.000000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dateTime  value\n",
       "index                                   \n",
       "0      2020-01-20 19:05:00.000000      0\n",
       "1      2020-01-20 19:38:00.000000      0\n",
       "2      2020-01-20 19:39:00.000000      0\n",
       "3      2020-01-20 19:40:00.000000      0\n",
       "4      2020-01-20 19:41:00.000000     61\n",
       "...                           ...    ...\n",
       "395    2020-01-21 06:57:00.000000     50\n",
       "396    2020-01-21 06:58:00.000000     65\n",
       "397    2020-01-21 06:59:00.000000     44\n",
       "398    2020-01-21 07:00:00.000000     10\n",
       "399    2020-01-21 07:01:00.000000     19\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_steps_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPARTURES_SCHEDULED</th>\n",
       "      <th>DEPARTURES_PERFORMED</th>\n",
       "      <th>PAYLOAD</th>\n",
       "      <th>SEATS</th>\n",
       "      <th>PASSENGERS</th>\n",
       "      <th>FREIGHT</th>\n",
       "      <th>MAIL</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>RAMP_TO_RAMP</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>...</th>\n",
       "      <th>Code_y</th>\n",
       "      <th>Plane_Group_Text</th>\n",
       "      <th>Code</th>\n",
       "      <th>Plane_Config_Text</th>\n",
       "      <th>origin_iata_code</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_lon</th>\n",
       "      <th>destination_iata_code</th>\n",
       "      <th>destination_lat</th>\n",
       "      <th>destination_lon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21502.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>IAD</td>\n",
       "      <td>38.944</td>\n",
       "      <td>-77.456</td>\n",
       "      <td>FLL</td>\n",
       "      <td>26.072</td>\n",
       "      <td>-80.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64506.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>IAD</td>\n",
       "      <td>38.944</td>\n",
       "      <td>-77.456</td>\n",
       "      <td>JFK</td>\n",
       "      <td>40.640</td>\n",
       "      <td>-73.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21502.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>IAH</td>\n",
       "      <td>29.980</td>\n",
       "      <td>-95.340</td>\n",
       "      <td>SAV</td>\n",
       "      <td>32.127</td>\n",
       "      <td>-81.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21502.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>ILM</td>\n",
       "      <td>34.271</td>\n",
       "      <td>-77.903</td>\n",
       "      <td>RDU</td>\n",
       "      <td>35.877</td>\n",
       "      <td>-78.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>IND</td>\n",
       "      <td>39.717</td>\n",
       "      <td>-86.294</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>BDL</td>\n",
       "      <td>41.939</td>\n",
       "      <td>-72.683</td>\n",
       "      <td>TUL</td>\n",
       "      <td>36.198</td>\n",
       "      <td>-95.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>BRO</td>\n",
       "      <td>25.907</td>\n",
       "      <td>-97.426</td>\n",
       "      <td>EWR</td>\n",
       "      <td>40.692</td>\n",
       "      <td>-74.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>BRO</td>\n",
       "      <td>25.907</td>\n",
       "      <td>-97.426</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>BRO</td>\n",
       "      <td>25.907</td>\n",
       "      <td>-97.426</td>\n",
       "      <td>IAH</td>\n",
       "      <td>29.980</td>\n",
       "      <td>-95.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>1</td>\n",
       "      <td>Passenger Configuration</td>\n",
       "      <td>BRO</td>\n",
       "      <td>25.907</td>\n",
       "      <td>-97.426</td>\n",
       "      <td>MIA</td>\n",
       "      <td>25.793</td>\n",
       "      <td>-80.291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DEPARTURES_SCHEDULED  DEPARTURES_PERFORMED   PAYLOAD  SEATS  \\\n",
       "index                                                                \n",
       "0                       0.0                   1.0   21502.0   76.0   \n",
       "1                       0.0                   3.0   64506.0  228.0   \n",
       "2                       0.0                   1.0   21502.0   76.0   \n",
       "3                       0.0                   1.0   21502.0   76.0   \n",
       "4                       0.0                   1.0   12500.0   50.0   \n",
       "...                     ...                   ...       ...    ...   \n",
       "395                     0.0                   1.0   35000.0  155.0   \n",
       "396                     0.0                   1.0   35000.0  155.0   \n",
       "397                     0.0                   4.0  140000.0  620.0   \n",
       "398                     0.0                   1.0   35000.0  155.0   \n",
       "399                     0.0                   4.0  140000.0  620.0   \n",
       "\n",
       "       PASSENGERS  FREIGHT  MAIL  DISTANCE  RAMP_TO_RAMP  AIR_TIME  ...  \\\n",
       "index                                                               ...   \n",
       "0             3.0      0.0   0.0     901.0         170.0     140.0  ...   \n",
       "1            75.0      0.0   0.0     228.0         219.0     140.0  ...   \n",
       "2            64.0      0.0   0.0     851.0         144.0     114.0  ...   \n",
       "3            55.0      0.0   0.0     122.0          58.0      31.0  ...   \n",
       "4            34.0      0.0   0.0     133.0          49.0      29.0  ...   \n",
       "...           ...      ...   ...       ...           ...       ...  ...   \n",
       "395          35.0      0.0   0.0    1304.0         250.0     215.0  ...   \n",
       "396           0.0      0.0   0.0    1679.0         212.0     199.0  ...   \n",
       "397           0.0      0.0   0.0    1224.0         649.0     585.0  ...   \n",
       "398           0.0      0.0   0.0     308.0          73.0      49.0  ...   \n",
       "399           0.0      0.0   0.0    1067.0         646.0     567.0  ...   \n",
       "\n",
       "      Code_y  Plane_Group_Text Code        Plane_Config_Text origin_iata_code  \\\n",
       "index                                                                           \n",
       "0          6     Jet, 2-Engine    1  Passenger Configuration              IAD   \n",
       "1          6     Jet, 2-Engine    1  Passenger Configuration              IAD   \n",
       "2          6     Jet, 2-Engine    1  Passenger Configuration              IAH   \n",
       "3          6     Jet, 2-Engine    1  Passenger Configuration              ILM   \n",
       "4          6     Jet, 2-Engine    1  Passenger Configuration              IND   \n",
       "...      ...               ...  ...                      ...              ...   \n",
       "395        6     Jet, 2-Engine    1  Passenger Configuration              BDL   \n",
       "396        6     Jet, 2-Engine    1  Passenger Configuration              BRO   \n",
       "397        6     Jet, 2-Engine    1  Passenger Configuration              BRO   \n",
       "398        6     Jet, 2-Engine    1  Passenger Configuration              BRO   \n",
       "399        6     Jet, 2-Engine    1  Passenger Configuration              BRO   \n",
       "\n",
       "      origin_lat origin_lon  destination_iata_code  destination_lat  \\\n",
       "index                                                                 \n",
       "0         38.944    -77.456                    FLL           26.072   \n",
       "1         38.944    -77.456                    JFK           40.640   \n",
       "2         29.980    -95.340                    SAV           32.127   \n",
       "3         34.271    -77.903                    RDU           35.877   \n",
       "4         39.717    -86.294                   None              NaN   \n",
       "...          ...        ...                    ...              ...   \n",
       "395       41.939    -72.683                    TUL           36.198   \n",
       "396       25.907    -97.426                    EWR           40.692   \n",
       "397       25.907    -97.426                   None              NaN   \n",
       "398       25.907    -97.426                    IAH           29.980   \n",
       "399       25.907    -97.426                    MIA           25.793   \n",
       "\n",
       "       destination_lon  \n",
       "index                   \n",
       "0              -80.153  \n",
       "1              -73.779  \n",
       "2              -81.202  \n",
       "3              -78.787  \n",
       "4                  NaN  \n",
       "...                ...  \n",
       "395            -95.888  \n",
       "396            -74.169  \n",
       "397                NaN  \n",
       "398            -95.340  \n",
       "399            -80.291  \n",
       "\n",
       "[400 rows x 62 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flights_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Use SQLAlchemy to write data in table_to_df_list to other database types\n",
    "\n",
    "Using a series of functions (defined below), I can now upload the SQLite tables (in DataFrame form) to each database. This process is simple for databases that support SQLAlchemy, but more complex for databases that do not. \n",
    "\n",
    "The function below, upload_to_database, uses the to_sql Pandas function to upload each table stored in table_to_df_list to a given database; the name for each table is sourced from sqlite_table_list. Tables already present in the databases are replaced. The function also outputs the length of time needed to upload all tables to the database.\n",
    "\n",
    "upload_to_database is compatible with databases that support SQLAlchemy. Within this program, it can be used with the AWS, GCP, and Azure database connections created above, and likely with the Heroku connection as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_database(table_to_df_list, con_for_export):\n",
    "    print(\"Uploading tables to database using the following connection:\",con_for_export)\n",
    "    upload_start_time = time.time()\n",
    "    for i in range(len(table_to_df_list)):\n",
    "        table_to_df_list[i].to_sql(sqlite_table_list[i], con = con_for_export, if_exists = 'replace') \n",
    "        # if_exists = 'replace' is meant to overwrite an older version of a table with the newer version. The storage logs on at least one database provider indicated that running this function caused an increase in my database size despite this replacement clause. However, this may have been due to other factors.\n",
    "    upload_end_time = time.time()\n",
    "    upload_run_time = upload_end_time - upload_start_time\n",
    "    upload_run_minutes = upload_run_time // 60\n",
    "    upload_run_seconds = upload_run_time % 60\n",
    "    print(\"Completed upload at\",time.ctime(upload_end_time),\"(local time)\")\n",
    "    print(\"Total run time:\",'{:.2f}'.format(upload_run_time),\"second(s) (\"+str(upload_run_minutes),\"minute(s) and\",'{:.2f}'.format(upload_run_seconds),\"second(s))\")\n",
    "\n",
    "# Amount of time needed to run this set of code (on my apartment's Ethernet connection):\n",
    "# AWS: 225.9s \n",
    "# GCP: 325.1s\n",
    "# Azure: 269.8s\n",
    "# Snowflake: 76.2s\n",
    "\n",
    "# It took 198.3 seconds when uploading an older but similar version of my database to Azure, but I was uploading the tables at the Butler Library at Columbia, where the WiFi\n",
    "# upload speed is faster than at home.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Snowflake import process was somewhat more involved due to the need to convert all columns to uppercase form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_snowflake(table_to_df_list):\n",
    "    print(\"Uploading tables to Snowflake\")\n",
    "    upload_start_time = time.time()    \n",
    "    con_for_export = snowflake_engine\n",
    "    from snowflake.connector.pandas_tools import pd_writer\n",
    "    for i in range(len(table_to_df_list)):\n",
    "    # From https://docs.snowflake.com/en/user-guide/python-connector-api.html\n",
    "    # pd_writer is necessary to include as the method\n",
    "        table_to_df_list[i].columns = list(map(str.upper, table_to_df_list[i].columns))  \n",
    "        # Columns need to be converted to uppercase so that they will work with Snowflake.\n",
    "        # This method comes from CodinginCircles at https://stackoverflow.com/a/63404628/13097194\n",
    "        table_to_df_list[i].to_sql(sqlite_table_list[i], con = con_for_export, if_exists = 'replace', index = False, method = pd_writer)\n",
    "    # Had to set index to False in order to avoid an error message explaining that Snowflake doesn't support indices\n",
    "    upload_end_time = time.time()\n",
    "    upload_run_time = upload_end_time - upload_start_time\n",
    "    upload_run_minutes = upload_run_time // 60\n",
    "    upload_run_seconds = upload_run_time % 60\n",
    "    print(\"Completed upload at\",time.ctime(upload_end_time),\"(local time)\")\n",
    "    print(\"Total run time:\",'{:.2f}'.format(upload_run_time),\"second(s) (\"+str(upload_run_minutes),\"minute(s) and\",'{:.2f}'.format(upload_run_seconds),\"second(s))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upload_to_airtable() function below is more complex than upload_to_databas() due to the use of batch_create in place of to_sql. The code only imports the music and flights tables from the SQLite database; the other two tables (in truncated form due to Airtable's capacity restrictions) were uploaded using the web interface, which may also have been the best way to upload the music and flights tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Airtable API documentation (https://pyairtable.readthedocs.io/en/latest/api.html#pyairtable.api.Api.batch_create) proved helpful in writing the following function.\n",
    "\n",
    "def upload_to_airtable():\n",
    "    airtable_base_id = 'appoqaUn0vZ1TeP31' # Found via link on API page\n",
    "    # that I accessed from my Account page\n",
    "\n",
    "    music_airtable = Table(airtable_key, airtable_base_id, 'music') \n",
    "    df_music_as_strings = table_to_df_list[sqlite_table_list.index('music')].copy().astype('str')\n",
    "# This change prevents an error from occurring during the Airtable upload process. \n",
    "# music_size is originally in int64 format, so I converted it to string format beforehand. The above code converts\n",
    "# all columns to strings, but these can be converted back to other types as \n",
    "# needed.\n",
    "    df_music_as_dict_list = []\n",
    "\n",
    "    for i in range(len(df_music_as_strings)):\n",
    "        df_music_as_dict_list.append(df_music_as_strings.iloc[i].to_dict())\n",
    "    music_airtable.batch_create(df_music_as_dict_list, typecast=True)\n",
    "\n",
    "\n",
    "    photos_airtable = Table(airtable_key, airtable_base_id, 'photos') \n",
    "    df_photos_as_dict_list = []\n",
    "\n",
    "    df_photos_as_strings = table_to_df_list[sqlite_table_list.index('photos')].copy().astype('str')\n",
    "    for i in range(len(df_photos_as_strings)):\n",
    "        df_photos_as_dict_list.append(df_photos_as_strings.iloc[i].to_dict())\n",
    "    photos_airtable.batch_create(df_photos_as_dict_list, typecast=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upload_to_databricks function uses pyodbc instead of SQLAlchemy. Although I was able to upload the photos, music, and steps tables to Databricks using the function, I ran into connectivity issues when uploading the flights table; as a result, I exported the flights table to a .csv file and uploaded it via the web interface instead. This method could also have been used for the other tables, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_databricks():\n",
    "    databricks_tables_query = databricks_pyodbc_cursor.execute(\"show tables in default\").fetchall() # Shows all tables currently within the Databricks database. https://spark.apache.org/docs/3.0.0-preview/sql-ref-syntax-aux-show-tables.html\n",
    "    databricks_table_list = [row[1] for row in databricks_tables_query] # databricks_tables_query returns a tuple for each table in the database. This list comprehension adds the 2nd entry within that row (containing the table name) into a new list.\n",
    "\n",
    "\n",
    "    if 'photos' in databricks_table_list: # Checks whether the table has already been created, and drops it if so\n",
    "        databricks_pyodbc_cursor.execute(\"Drop table photos\")\n",
    "\n",
    "    databricks_pyodbc_cursor.execute(\"CREATE TABLE photos(file_name string, size float, created_date string, modified_date string, gcs_url string);\") # Took 47 seconds\n",
    "\n",
    "    databricks_pyodbc_cursor.fast_executemany = True\n",
    "    databricks_pyodbc_cursor.executemany(\"insert into photos(file_name, size, created_date, modified_date, gcs_url) values (?, ?, ?, ?, ?)\", table_to_df_list[sqlite_table_list.index('photos')].values.tolist())\n",
    "    # The above line is based on https://github.com/mkleehammer/pyodbc/wiki/Cursor\n",
    "    # The idea of using .values.tolist() to convert a Pandas DataFrame into a sequence that would work with executemany came from ansen at https://stackoverflow.com/a/30185727/13097194\n",
    "    # An alternative to tolist() would be to use .iloc or .loc to locate and add each value individually, but .values.tolist() is much simpler.\n",
    "    # index('photos') retrieves the index number corresponding to the location of the 'photos' table within table_to_df_list.\n",
    "\n",
    "    if 'music' in databricks_table_list(): # Checks whether the table has already been created, and drops it if so\n",
    "        databricks_pyodbc_cursor.execute(\"Drop table music\")\n",
    "\n",
    "    databricks_pyodbc_cursor.execute(\"CREATE TABLE music(music_file_name string, music_size float, music_created_date string, music_modified_date string, music_gcs_url string);\") # Took 47 seconds\n",
    "    databricks_pyodbc_cursor.fast_executemany = True\n",
    "    databricks_pyodbc_cursor.executemany(\"insert into music(music_file_name, music_size, music_created_date, music_modified_date, music_gcs_url) values (?, ?, ?, ?, ?)\", table_to_df_list[sqlite_table_list.index('music')].values.tolist())\n",
    "\n",
    "    if 'steps' in databricks_table_list(): # Checks whether the table has already been created, and drops it if so\n",
    "        databricks_pyodbc_cursor.execute(\"Drop table steps\")\n",
    "\n",
    "    databricks_pyodbc_cursor.execute(\"CREATE TABLE steps(dateTime string, value int);\")\n",
    "    for i in range(0, 500000, 100000): # This for loop allows rows to be uploaded in chunks. This method was chosen because trying to upload all 529,256 rows at once from the steps table resulted in errors.\n",
    "        databricks_pyodbc_cursor.fast_executemany = True\n",
    "        start_time = time.time()\n",
    "        print(\"Now uploading rows\",i,\"to\",i+99999) # i+100000 won't be added during this iteration of the loop due to how slice notation works in Python.\n",
    "        databricks_pyodbc_cursor.executemany(\"insert into steps(dateTime, value) values (?, ?)\", table_to_df_list[sqlite_table_list.index('steps')].iloc[i:i+100000].values.tolist())\n",
    "        end_time = time.time()\n",
    "        print(\"Time (in seconds) to upload this set of rows:\",end_time-start_time)\n",
    "    print(\"Now uploading rows 500,000 to 529,255:\")\n",
    "    databricks_pyodbc_cursor.executemany(\"insert into steps(dateTime, value) values (?, ?)\", table_to_df_list[sqlite_table_list.index('steps')].iloc[500000:529256].values.tolist())\n",
    "\n",
    "    # The steps upload code took 6m55.9s to run when uploading 10000 rows at a time, but only 2m2.9 s when uploading 100,000 rows at a time. (This was partly because the code started uploading rows earlier within the 100,000 row condition, which I imagine was just due to random chance.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating code to upload the flights table required more preparatory work. Unfortunately, due to connection errors that arose during the upload process, I was not able to run this code successfully. However, it could theoretically work in the absence of connectivity problems, so I have included it in commented form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Because there are 62 columns within the flights table, I did not want to manually type out the column names and types when defining the tables, nor did I want to type exactly 62 question marks as part of the table population process. Instead, I used code to generate variables storing these strings, then inserted those variables into the SQL queries.\n",
    "\n",
    "# databricks_tables_query = databricks_pyodbc_cursor.execute(\"show tables in default\").fetchall() # Shows all tables currently within the Databricks database. https://spark.apache.org/docs/3.0.0-preview/sql-ref-syntax-aux-show-tables.html\n",
    "# databricks_table_list = [row[1] for row in databricks_tables_query] # databricks_tables_query returns a tuple for each table in the database. This list comprehension adds the 2nd entry within that row (containing the table name) into a new list.\n",
    "\n",
    "\n",
    "# string_for_flights_table_definition = \" string, \".join(table_to_df_list[sqlite_table_list.index('flights')].columns)\n",
    "# string_for_flights_table_definition+= ' string'\n",
    "# print(string_for_flights_table_definition)\n",
    "\n",
    "# question_marks_for_flights_table_population = '?' + (', ?' * 61)\n",
    "# print(question_marks_for_flights_table_population)\n",
    "\n",
    "# string_for_flights_table_population = \", \".join(table_to_df_list[sqlite_table_list.index('flights')].columns)\n",
    "# print(string_for_flights_table_population)\n",
    "\n",
    "# # The following code was meant to create and populate the flights table, but I encountered multiple connection errors when trying to run it; therefore, I instead imported this table using the Databricks web UI. I originally tried to use executemany to add 100,000 rows at a time, but received an Out of Memory error (likely because there were 62 columns per row). Therefore, I modified the code to add only 10,000 rows at a time. I later increased it to 50,000 rows. Regardless of the setting I chose, however, I continued to encounter error messages that appeared related to the connection to Databricks. More debugging may have resolved these issues.\n",
    "\n",
    "# if 'flights' in databricks_table_list: # Checks whether the database has already been created\n",
    "#     databricks_pyodbc_cursor.execute(\"Drop table flights\")\n",
    "# databricks_pyodbc_cursor.execute(\"CREATE TABLE flights(\"+string_for_flights_table_definition+\");\")\n",
    "\n",
    "# df_flights_as_strings_to_list = table_to_df_list[sqlite_table_list.index('flights')].astype('str').values.tolist() # Changing the DataFrame columns to string types and converting the output to a list beforehand may save time.\n",
    "# # The idea of using tolist() to convert a Pandas DataFrame into a sequence that would work with executemany came from ansen at https://stackoverflow.com/a/30185727/13097194\n",
    "# # Changed the type of each column to a string in order to avoid type compatibility errors\n",
    "\n",
    "\n",
    "# for i in range(0, 450000, 50000):\n",
    "#     databricks_pyodbc_cursor.fast_executemany = True\n",
    "#     start_time = time.time()\n",
    "#     print(\"Now uploading rows\",i,\"to\",i+49999) \n",
    "#     databricks_pyodbc_cursor.executemany(\"insert into flights(\"+string_for_flights_table_population+\") values (\"+question_marks_for_flights_table_population+\")\", df_flights_as_strings_to_list[0:50000])\n",
    "#     end_time = time.time()\n",
    "#     print(\"Time (in seconds) to upload this set of rows:\",end_time-start_time)\n",
    "# print(\"Now uploading rows 450,000 to 482,273:\")   \n",
    "# databricks_pyodbc_cursor.executemany(\"insert into flights(\"+string_for_flights_table_population+\") values (\"+question_marks_for_flights_table_population+\")\", df_flights_as_strings_to_list[450000:482274])\n",
    "\n",
    "# # I received an error message that appeared to relate to a connection issue, so I restarted both my Jupyter Notebook kernel and the Databricks cluster. I also changed the Databricks timeout time from 40 minutes to 400 minutes so that a timeout wouldn't occur during this operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_to_df_list[sqlite_table_list.index('flights')].to_csv('flights_table.csv') # Exports the flights table to .csv format so that it can be uploaded to Databricks using the web UI. Alternately, you can upload the routes_planes_coordinates.csv file to Databricks, as this file was the original source of the flights table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code shows how, when adding tables into Databricks, a for loop could be used in place of executemany(). However, this code took quite a while to run; hence, executemany() appears to be the better option (and also a simpler one). For example, this code took 257.2 seconds to execute compared to only 14.1 when fast_executemany was set to True and executemany was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# databricks_pyodbc_cursor.execute(\"Drop table music\")\n",
    "\n",
    "# if 'music' not in databricks_table_list(): # Checks whether the database has already been created\n",
    "#     databricks_pyodbc_cursor.execute(\"CREATE TABLE music(music_file_name string, music_size float, music_created_date string, music_modified_date string, music_gcs_url string);\") # Took 47 seconds\n",
    "\n",
    "#     for i in range(len(table_to_df_list[sqlite_table_list.index('music')])):\n",
    "#         databricks_pyodbc_cursor.execute(\"insert into music(music_file_name, music_size, music_created_date, music_modified_date, music_gcs_url) values (?, ?, ?, ?, ?)\", table_to_df_list[sqlite_table_list.index('music')].iloc[i].astype(str).tolist())\n",
    "#         # The above line is based on https://github.com/mkleehammer/pyodbc/wiki/Cursor\n",
    "#         # 'astype(str)' was added in to avoid an error related to int64 values. See https://stackoverflow.com/a/68504686/13097194\n",
    "\n",
    "# else:\n",
    "#     print(\"Table already present within database. Drop the table in order to update it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block of code calls the above upload functions for all databases whose upload flags (defined earlier in the code) are set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Uploading tables to AWS\n",
      "Uploading tables to database using the following connection: Engine(postgresql://kburchfiel:***@kb-cheaper-aws-db.cquawwv3qwid.us-east-1.rds.amazonaws.com:5432/postgres)\n",
      "Completed upload at Mon Nov  8 21:50:57 2021 (local time)\n",
      "Total run time: 251.78 second(s) (4.0 minute(s) and 11.78 second(s))\n",
      "\n",
      " Uploading tables to GCP\n",
      "Uploading tables to database using the following connection: Engine(postgresql://kb_gcp_db:***@34.135.185.218:5432/postgres)\n",
      "Completed upload at Mon Nov  8 21:55:39 2021 (local time)\n",
      "Total run time: 281.70 second(s) (4.0 minute(s) and 41.70 second(s))\n",
      "\n",
      " Uploading tables to Azure\n",
      "Uploading tables to database using the following connection: Engine(postgresql://kbindstudy:***@kb-ind-study-azure-server.postgres.database.azure.com/postgres?sslmode=require)\n",
      "Completed upload at Mon Nov  8 22:00:26 2021 (local time)\n",
      "Total run time: 286.63 second(s) (4.0 minute(s) and 46.63 second(s))\n"
     ]
    }
   ],
   "source": [
    "if upload_to_aws == True:\n",
    "    print(\"\\n Uploading tables to AWS\")\n",
    "    upload_to_database(table_to_df_list = table_to_df_list, con_for_export = aws_sqlalchemy_psql_engine)\n",
    "\n",
    "if upload_to_gcp == True:\n",
    "    print(\"\\n Uploading tables to GCP\")\n",
    "    upload_to_database(table_to_df_list = table_to_df_list, con_for_export = gcp_sqlalchemy_psql_engine)\n",
    "\n",
    "if upload_to_azure == True:\n",
    "    print(\"\\n Uploading tables to Azure\")\n",
    "    upload_to_database(table_to_df_list = table_to_df_list, con_for_export = azure_sqlalchemy_psql_engine)\n",
    "\n",
    "if upload_to_heroku == True:\n",
    "    print(\"\\n Uploading tables to Heroku\")\n",
    "    upload_to_database(table_to_df_list = table_to_df_list, con_for_export = heroku_sqlalchemy_psql_engine)\n",
    "\n",
    "if upload_to_snowflake == True:\n",
    "    print(\"\\n Uploading tables to Snowflake\")\n",
    "    upload_to_snowflake(table_to_df_list = table_to_df_list)\n",
    "\n",
    "if upload_to_airtable == True:\n",
    "    print(\"\\n Uploading tables to Airtable\")\n",
    "    upload_to_airtable()\n",
    "\n",
    "if upload_to_databricks == True:\n",
    "    print(\"\\n Uploading tables to Databricks\")\n",
    "    upload_to_databricks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran upload_to_database for AWS, GCP, and Azure back-to-back, I obtained the following upload times:\n",
    "\n",
    "AWS: 247.55s (4m7.55s)\n",
    "GCP: 282.12s (4m42.12s)\n",
    "Azure: 293.15s (4m53.15s)\n",
    "\n",
    "The flights, steps, music, and photos tables did not exist in these databases prior to this upload, but I obtained similar times when pre-existing copies of the tables were already present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of alternate import strategies using psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two functions below show two ways of using psycopg2 to upload the flights table to the Azure database. My preference is to use to_sql instead given its simplicity, but a demonstration of psycopg2's functionality may still be helpful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_azure_flights_import():\n",
    "\n",
    "# Because there are 62 columns within the flights table, I did not want to manually type out the column names and types when defining the tables, nor did I want to type exactly 62 question marks as part of the table population process. Instead, I used code to generate variables storing these strings, then inserted those variables into the ensuing SQL queries.\n",
    "\n",
    "    string_for_flights_table_definition = \" text, \".join(table_to_df_list[sqlite_table_list.index('flights')].columns)\n",
    "    string_for_flights_table_definition+= ' text'\n",
    "    print(string_for_flights_table_definition)\n",
    "\n",
    "    question_marks_for_flights_table_population = '%s' + (', %s' * 61) \n",
    "    print(question_marks_for_flights_table_population)\n",
    "\n",
    "    string_for_flights_table_population = \", \".join(table_to_df_list[sqlite_table_list.index('flights')].columns)\n",
    "    print(string_for_flights_table_population)\n",
    "\n",
    "    azure_tables_query = pd.read_sql(\"Select tablename from pg_tables where schemaname = 'public'\", con = psycopg2_azure_connection) # From https://stackoverflow.com/a/24462829/13097194 and https://www.postgresql.org/docs/current/infoschema-tables.html\n",
    "    azure_table_list = azure_tables_query['tablename'].tolist()\n",
    "    print(\"Current list of tables:\")\n",
    "    print(azure_table_list)\n",
    "    if 'flights_psycopg2' in azure_table_list: # Checks whether the database has already been created\n",
    "        psycopg2_azure_cursor.execute(\"Drop table flights_psycopg2;\")\n",
    "        psycopg2_azure_connection.commit()\n",
    "    psycopg2_azure_cursor.execute(\"CREATE TABLE flights_psycopg2(\"+string_for_flights_table_definition+\");\")\n",
    "\n",
    "    df_flights_as_strings_to_list = table_to_df_list[sqlite_table_list.index('flights')].astype('str').values.tolist() \n",
    "    # The idea of using tolist() to convert a Pandas DataFrame into a sequence that would work with executemany came from ansen at https://stackoverflow.com/a/30185727/13097194\n",
    "    # Changing the DataFrame columns to string types (in order to avoid type compatibility errors) and converting the output to a list beforehand should save time compared to making this change each time the following for loop runs.\n",
    "\n",
    "\n",
    "    new_start_time = time.time()\n",
    "    for i in range(len(df_flights_as_strings_to_list)):\n",
    "        psycopg2_azure_cursor.execute(\"insert into flights_psycopg2(\"+string_for_flights_table_population+\") values (\"+question_marks_for_flights_table_population+\")\", df_flights_as_strings_to_list[i])\n",
    "        # The above line is based on https://www.psycopg.org/docs/usage.html . Note that variables were used in place of hard-coded table columns, which saved me the trouble of having to write out those tables manually.\n",
    "\n",
    "        # The timing script below allows the function's progress to be tracked.\n",
    "        if i % 1000 == 0:\n",
    "            new_end_time = time.time()\n",
    "            print(\"Uploaded\",i,\"rows so far.\")\n",
    "            print(\"Time (in seconds) elapsed so far:\",new_end_time-new_start_time)\n",
    "\n",
    "    psycopg2_azure_connection.commit() # Necessary in order to keep the newly created table within the database after the program ends\n",
    "    \n",
    "    # This code ended up taking 230 minutes (3h50m) and 46.2 seconds to run! During a subsequent run, it took 205m (3h25m) and 6.5 seconds. Clearly, this isn't the most efficient way to upload tables using psycopg2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function runs considerably faster than the previous one, as it uses execute_batch rather than execute. See the above function for additional comments and citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_azure_flights_import_execute_batch():\n",
    "    string_for_flights_table_definition = \" text, \".join(table_to_df_list[sqlite_table_list.index('flights')].columns)\n",
    "    string_for_flights_table_definition+= ' text'\n",
    "    print(string_for_flights_table_definition)\n",
    "\n",
    "    question_marks_for_flights_table_population = '%s' + (', %s' * 61)\n",
    "    print(question_marks_for_flights_table_population)\n",
    "\n",
    "    string_for_flights_table_population = \", \".join(table_to_df_list[sqlite_table_list.index('flights')].columns)\n",
    "    print(string_for_flights_table_population)\n",
    "    print(\"Creating list of tables already present in the database:\")\n",
    "    azure_tables_query = pd.read_sql(\"Select tablename from pg_tables where schemaname = 'public'\", con = psycopg2_azure_connection) # From https://stackoverflow.com/a/24462829/13097194 and https://www.postgresql.org/docs/current/infoschema-tables.html\n",
    "    azure_table_list = azure_tables_query['tablename'].tolist()\n",
    "    print(\"Current list of tables:\")\n",
    "    print(azure_table_list)\n",
    "    print(\"Checking whether flights_psycopg2 is already in the list:\")\n",
    "\n",
    "    if 'flights_psycopg2' in azure_table_list: # Checks whether the database has already been created\n",
    "        print(\"Dropping pre-existing copy of flights_psycopg2 from database:\")\n",
    "        psycopg2_azure_cursor.execute(\"Drop table flights_psycopg2;\")\n",
    "        # Adding a semicolon here may have been necessary\n",
    "        # in order to prevent the code from hanging.\n",
    "        psycopg2_azure_connection.commit()\n",
    "    print(\"Creating new copy of flights_psycopg2:\")\n",
    "    psycopg2_azure_cursor.execute(\"CREATE TABLE flights_psycopg2(\"+string_for_flights_table_definition+\");\")\n",
    "\n",
    "    print(\"converting table to list\")\n",
    "    df_flights_as_strings_to_list = table_to_df_list[sqlite_table_list.index('flights')].astype('str').values.tolist() \n",
    "\n",
    "    new_start_time = time.time()\n",
    "    print(\"Now uploading rows\") \n",
    "    psycopg2.extras.execute_batch(psycopg2_azure_cursor, \"insert into flights_psycopg2(\"+string_for_flights_table_population+\") values (\"+question_marks_for_flights_table_population+\")\", df_flights_as_strings_to_list, page_size = 1000) # See https://www.psycopg.org/docs/extras.html#fast-exec\n",
    "    new_end_time = time.time()\n",
    "    print(\"Time (in seconds) elapsed:\",new_end_time-new_start_time)\n",
    "\n",
    "    psycopg2_azure_connection.commit() \n",
    "\n",
    "    # This block of code took 6 minutes and 59.1 seconds to run with page_size set to 10000, and 7 minutes and 15.4 seconds to run with page_size set to 1000. (Some other changes were made to this cell in between the two runs.) Meanwhile, using to_sql to upload just the flights table to the Azure database took 4 minutes and 5.8 seconds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following commented-out lines can be used to test out these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psycopg2_azure_cursor.execute(\"Drop table flights_psycopg2;\")\n",
    "# psycopg2_azure_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# azure_tables_query = pd.read_sql(\"Select tablename from pg_tables where schemaname = 'public'\", con = psycopg2_azure_connection) # From https://stackoverflow.com/a/24462829/13097194 and https://www.postgresql.org/docs/current/infoschema-tables.html\n",
    "# azure_table_list = azure_tables_query['tablename'].tolist()\n",
    "# print(\"Current list of tables:\")\n",
    "# print(azure_table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt_azure_flights_import() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psycopg2_azure_cursor.execute(\"drop table flights_psycopg2\")\n",
    "# psycopg2_azure_connection.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_of_psycopg2 = pd.read_sql(\"Select * from flights_psycopg2\", con=psycopg2_azure_connection)\n",
    "# test_of_psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Test out database imports\n",
    "\n",
    "Finally, the following code blocks make it possible to test whether data was successfully uploaded to 6 of the above databases. Because I found Airtable to be limited as a database host, I did not create an import function for it. If you choose to create one, consider applying pyAirtable's .all() function: https://pyairtable.readthedocs.io/en/latest/api.html\n",
    "\n",
    "For comparisons of the time needed to import these databases and execute other queries on them, see the Database Query Timer notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_db(table_list, con_for_import):\n",
    "    print(\"Importing tables from database using the following connection:\",con_for_import)\n",
    "    import_start_time = time.time() \n",
    "    imported_table_df_list = [] \n",
    "    for table in table_list:\n",
    "        imported_df = pd.read_sql(\"select * from \"+table+\";\", con=con_for_import)\n",
    "        if imported_df.columns[0] == 'index': # If the table already has an index\n",
    "            # column, set that column as the index.\n",
    "            imported_df.set_index('index',inplace=True)\n",
    "        else: # Otherwise, if the index column is unnamed, give it the name 'index.'\n",
    "            imported_df.index.name = 'index'\n",
    "        imported_table_df_list.append(imported_df)\n",
    "    import_end_time = time.time()\n",
    "    import_run_time = import_end_time - import_start_time\n",
    "    import_run_minutes = import_run_time // 60\n",
    "    import_run_seconds = import_run_time % 60\n",
    "    print(\"Completed import at\",time.ctime(import_end_time),\"(local time)\")\n",
    "    print(\"Total run time:\",'{:.2f}'.format(import_run_time),\"second(s) (\"+str(import_run_minutes),\"minute(s) and\",'{:.2f}'.format(import_run_seconds),\"second(s))\")\n",
    "    return (imported_table_df_list, import_run_time) \n",
    "    # These components could also be returned as a list or class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each database, read_from_db will only be called if the database's import flag is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing tables from database using the following connection: Engine(snowflake://KBURCHFIEL:***@RV85777.east-us-2.azure/KB_SNOWFLAKE_DB/PUBLIC)\n",
      "Completed import at Mon Nov  8 21:46:17 2021 (local time)\n",
      "Total run time: 57.57 second(s) (0.0 minute(s) and 57.57 second(s))\n"
     ]
    }
   ],
   "source": [
    "if import_from_aws == True:\n",
    "    aws_imported_table_list, aws_run_time = read_from_db(sqlite_table_list, con_for_import = aws_sqlalchemy_psql_engine)\n",
    "    \n",
    "if import_from_gcp == True:\n",
    "    gcp_imported_table_list, gcp_run_time = read_from_db(sqlite_table_list, con_for_import = gcp_sqlalchemy_psql_engine)\n",
    "    \n",
    "if import_from_azure == True:\n",
    "    azure_imported_table_list, azure_run_time = read_from_db(sqlite_table_list, con_for_import = azure_sqlalchemy_psql_engine)\n",
    "    \n",
    "if import_from_heroku == True:\n",
    "    heroku_imported_table_list, heroku_run_time = read_from_db(sqlite_table_list, con_for_import = heroku_sqlalchemy_psql_engine)\n",
    "    \n",
    "if import_from_snowflake == True:\n",
    "    snowflake_imported_table_list, snowflake_run_time = read_from_db(sqlite_table_list, con_for_import = snowflake_engine)\n",
    "    \n",
    "if import_from_databricks == True:\n",
    "    databricks_imported_table_list, databricks_run_time = read_from_db(sqlite_table_list, con_for_import = databricks_pyodbc_connection)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_from_db returns a list of DataFrames, each of which stores a particular table. The commented-out code blocks below show how to access and examine these tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported_table_list = aws_imported_table_list.copy()\n",
    "# imported_table_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departures_scheduled</th>\n",
       "      <th>departures_performed</th>\n",
       "      <th>payload</th>\n",
       "      <th>seats</th>\n",
       "      <th>passengers</th>\n",
       "      <th>freight</th>\n",
       "      <th>mail</th>\n",
       "      <th>distance</th>\n",
       "      <th>ramp_to_ramp</th>\n",
       "      <th>air_time</th>\n",
       "      <th>...</th>\n",
       "      <th>code_y</th>\n",
       "      <th>plane_group_text</th>\n",
       "      <th>code</th>\n",
       "      <th>plane_config_text</th>\n",
       "      <th>origin_iata_code</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_lon</th>\n",
       "      <th>destination_iata_code</th>\n",
       "      <th>destination_lat</th>\n",
       "      <th>destination_lon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138035.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60427.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>MFE</td>\n",
       "      <td>26.176</td>\n",
       "      <td>-98.239</td>\n",
       "      <td>LIT</td>\n",
       "      <td>34.729</td>\n",
       "      <td>-92.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>187270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103389.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>MSP</td>\n",
       "      <td>44.880</td>\n",
       "      <td>-93.217</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181759.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>OKC</td>\n",
       "      <td>35.393</td>\n",
       "      <td>-97.601</td>\n",
       "      <td>DFW</td>\n",
       "      <td>32.896</td>\n",
       "      <td>-97.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>241160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82038.0</td>\n",
       "      <td>48462.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>OMA</td>\n",
       "      <td>41.302</td>\n",
       "      <td>-95.894</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101921.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>ONT</td>\n",
       "      <td>34.056</td>\n",
       "      <td>-117.601</td>\n",
       "      <td>MHR</td>\n",
       "      <td>38.554</td>\n",
       "      <td>-121.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482268</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>188880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47615.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>HNL</td>\n",
       "      <td>21.316</td>\n",
       "      <td>-157.927</td>\n",
       "      <td>ONT</td>\n",
       "      <td>34.056</td>\n",
       "      <td>-117.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482269</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>246417.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100673.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>LAN</td>\n",
       "      <td>42.779</td>\n",
       "      <td>-84.587</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482270</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>140401.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>LAS</td>\n",
       "      <td>36.080</td>\n",
       "      <td>-115.152</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482271</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>147871.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>LRD</td>\n",
       "      <td>27.544</td>\n",
       "      <td>-99.461</td>\n",
       "      <td>DFW</td>\n",
       "      <td>32.896</td>\n",
       "      <td>-97.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482272</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>254323.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Jet, 2-Engine</td>\n",
       "      <td>2</td>\n",
       "      <td>Freight Configuration</td>\n",
       "      <td>MDT</td>\n",
       "      <td>40.193</td>\n",
       "      <td>-76.763</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482273 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        departures_scheduled  departures_performed   payload  seats  \\\n",
       "index                                                                 \n",
       "0                        2.0                   2.0  138035.0    0.0   \n",
       "1                        2.0                   2.0  187270.0    0.0   \n",
       "2                        2.0                   2.0  181759.0    0.0   \n",
       "3                        2.0                   2.0  241160.0    0.0   \n",
       "4                        2.0                   2.0  184573.0    0.0   \n",
       "...                      ...                   ...       ...    ...   \n",
       "482268                   2.0                   2.0  188880.0    0.0   \n",
       "482269                   2.0                   2.0  246417.0    0.0   \n",
       "482270                   2.0                   2.0  140401.0    0.0   \n",
       "482271                   2.0                   2.0  147871.0    0.0   \n",
       "482272                   2.0                   2.0  254323.0    0.0   \n",
       "\n",
       "        passengers   freight     mail  distance  ramp_to_ramp  air_time  ...  \\\n",
       "index                                                                    ...   \n",
       "0              0.0   60427.0      0.0     690.0         203.0     181.0  ...   \n",
       "1              0.0  103389.0      0.0     278.0         115.0      81.0  ...   \n",
       "2              0.0   47551.0      0.0     175.0          96.0      66.0  ...   \n",
       "3              0.0   82038.0  48462.0     582.0         209.0     154.0  ...   \n",
       "4              0.0  101921.0      0.0     372.0         144.0     116.0  ...   \n",
       "...            ...       ...      ...       ...           ...       ...  ...   \n",
       "482268         0.0   47615.0      0.0    2603.0         648.0     593.0  ...   \n",
       "482269         0.0  100673.0      0.0     323.0         122.0     103.0  ...   \n",
       "482270         0.0   73540.0      0.0    1624.0         380.0     349.0  ...   \n",
       "482271         0.0   34010.0      0.0     396.0         153.0     111.0  ...   \n",
       "482272         0.0  120154.0      0.0     501.0         227.0     165.0  ...   \n",
       "\n",
       "       code_y  plane_group_text code      plane_config_text origin_iata_code  \\\n",
       "index                                                                          \n",
       "0           6     Jet, 2-Engine    2  Freight Configuration              MFE   \n",
       "1           6     Jet, 2-Engine    2  Freight Configuration              MSP   \n",
       "2           6     Jet, 2-Engine    2  Freight Configuration              OKC   \n",
       "3           6     Jet, 2-Engine    2  Freight Configuration              OMA   \n",
       "4           6     Jet, 2-Engine    2  Freight Configuration              ONT   \n",
       "...       ...               ...  ...                    ...              ...   \n",
       "482268      6     Jet, 2-Engine    2  Freight Configuration              HNL   \n",
       "482269      6     Jet, 2-Engine    2  Freight Configuration              LAN   \n",
       "482270      6     Jet, 2-Engine    2  Freight Configuration              LAS   \n",
       "482271      6     Jet, 2-Engine    2  Freight Configuration              LRD   \n",
       "482272      6     Jet, 2-Engine    2  Freight Configuration              MDT   \n",
       "\n",
       "       origin_lat origin_lon  destination_iata_code  destination_lat  \\\n",
       "index                                                                  \n",
       "0          26.176    -98.239                    LIT           34.729   \n",
       "1          44.880    -93.217                   None              NaN   \n",
       "2          35.393    -97.601                    DFW           32.896   \n",
       "3          41.302    -95.894                   None              NaN   \n",
       "4          34.056   -117.601                    MHR           38.554   \n",
       "...           ...        ...                    ...              ...   \n",
       "482268     21.316   -157.927                    ONT           34.056   \n",
       "482269     42.779    -84.587                   None              NaN   \n",
       "482270     36.080   -115.152                   None              NaN   \n",
       "482271     27.544    -99.461                    DFW           32.896   \n",
       "482272     40.193    -76.763                   None              NaN   \n",
       "\n",
       "        destination_lon  \n",
       "index                    \n",
       "0               -92.224  \n",
       "1                   NaN  \n",
       "2               -97.037  \n",
       "3                   NaN  \n",
       "4              -121.297  \n",
       "...                 ...  \n",
       "482268         -117.601  \n",
       "482269              NaN  \n",
       "482270              NaN  \n",
       "482271          -97.037  \n",
       "482272              NaN  \n",
       "\n",
       "[482273 rows x 62 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# snowflake_imported_table_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "run_minutes = run_time // 60\n",
    "run_seconds = run_time % 60\n",
    "print(\"Completed run at\",time.ctime(end_time),\"(local time)\")\n",
    "print(\"Total run time:\",'{:.2f}'.format(run_time),\"second(s) (\"+str(run_minutes),\"minute(s) and\",'{:.2f}'.format(run_seconds),\"second(s))\") # Only meaningful when the program is run nonstop from start to finish\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a016a462c2a18f177a2554c94a9e2d8b52c0ae6e623363f8138b3d5b2656021"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ga15pyd': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
